# Tracking objects using key points

## Цель работы

Целью данной работы является изучение и реализация алгоритма трекинга объекта по ключевым точкам. Было необходимо на первом кадре видео определить ключевые точки объекта и по ним отслеживать положение предмета на изображении. В рамках задания были разработан механизм, основывающийся на поиске ключевых точек через SIFT-алгоритм.

Полученная реализация была протестирована: были построены видеозаписи, иллюстрирующие работу алгоритма. 

---

## 1. Теоретическая база

В качестве алгоритма для поиска и описания ключевых точек был использован метод SIFT (Scale-Invariant Feature Transform), предложенный Дэвидом Лоу в 1999 году. Метод обеспечивает устойчивое обнаружение особенностей, инвариантных к масштабу, повороту и частично — к изменению освещения и аффинным искажениям.

Основные этапы алгоритма SIFT:

Обнаружение экстремумов в масштабном пространстве — строится пирамида разностей гауссианов (DoG), в которой ищутся устойчивые ключевые точки как локальные экстремумы.
Уточнение положения ключевых точек — применяется интерполяция для повышения точности координат и подавления ненадёжных точек (например, находящихся на краях).
Определение ориентации — вокруг каждой ключевой точки вычисляется гистограмма градиентов, по которой задаётся доминирующая ориентация, обеспечивающая инвариантность к повороту.
Построение дескриптора — формируется 128-мерный вектор на основе градиентов в окрестности точки, разделённой на подобласти, что обеспечивает устойчивость к локальным деформациям и шуму.
Использованные материалы:

- Документация OpenCV: https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html
- Статья о реализации метода SIFT: https://habr.com/ru/articles/106302/
---

## Описание разработанной системы

### Архитектура проекта
```
.
├── input/ # place videos here
├── output/ # generated videos
├── tracking.ipynb # core implementations
└── README.md # report
```

### Описание алгоритма

## Описание алгоритма

Алгоритм отслеживает объект на видео с использованием признаков SIFT и гомографии.

### Основные шаги

1. **Инициализация**  
   С первого кадра извлекаются ключевые точки и дескрипторы SIFT. По ним строится начальный bounding box.

2. **Сопоставление признаков**  
   В каждом новом кадре вычисляются SIFT-дескрипторы и сопоставляются с исходными с помощью FLANN-матчера (с фильтрацией по критерию Лоу).

3. **Оценка движения**  
   При достаточном числе совпадений (`>10`) вычисляется гомография (RANSAC), и bounding box переносится на новый кадр через `cv.perspectiveTransform`.

4. **Обновление опорных признаков**  
   Только точки, попавшие внутрь нового bounding box, становятся опорными для следующего кадра — это повышает устойчивость к выбросам и смещению объекта.

5. **Визуализация**  
   На кадр наносится зелёный контур bounding box и метка `"Object"`. Результат записывается в `output1.avi`.

### Особенности

- Используется SIFT с параметрами: `contrastThreshold=0.03`, `edgeThreshold=10`, `sigma=1.6`.
- Отслеживание устойчиво к повороту, масштабу и частичным изменениям внешнего вида.
- Проверка принадлежности точки области — через `cv.pointPolygonTest`.

---
## 4. Обсуждение результатов

Алгоритм был протестирован на 4 видео: обычном видещ, видео с шумами, видео с блюром и пользовательским видео. Механизм хорошо работает с выбросами и блюром - качество трекинга сильно не меняется. Однако при изменении масштаба может меняться форма рамки. 
Данная особенность обусловлена тем, что при изменении масштаба или ракурса объекта в кадре возникают перспективные искажения. Алгоритм использует гомографию для переноса bounding box’а между кадрами, которая учитывает эту перспективу. В результате рамка перестаёт оставаться прямоугольной и может принимать произвольную четырёхугольную форму — что на самом деле отражает реальное положение и ориентацию объекта в трёхмерном пространстве.
На пользовательском видео так же продемонстрировано высокое качество работы алгоритма.

## 5. Выводы

В ходе работы было выполнено:

- Разработка алгоритма трекинга объекта на видео 
- Тестирование на реальных данных   
- Визуализация результатов

**Основной вывод:**  
Разработанный алгоритм оказался устойчив к простейшим видам движения (например поворот, масштаб или перенос). Однако данный алгоритм не учитывает возможность удаления объекта с видеозаписи. Если такое случается, то трекинг нарушается. Так же при слишком сильном отдалении объекта точки не всегда могут распознаться, поэтому приходится сохранять страую рамку, чтобы алгоритм был устойчив.

---

## 6. Использованные источники

1. David G. Lowe. "Distinctive Image Features from Scale-Invariant Keypoints"
   https://doi.org/10.1023/B:VISI.0000029664.99615.94?spm=a2ty_o01.29997173.0.0.25cd5171F2PIq6&file=B:VISI.0000029664.99615.94

3. OpenCV documentation  
   https://docs.opencv.org/

4. Детектор и дескриптор SIFT: алгоритм и принцип работы
   https://habr.com/ru/articles/106302/ 
---
