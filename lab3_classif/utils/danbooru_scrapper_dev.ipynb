{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://danbooru.donmai.us/\"\n",
    "TEST_URL = \"https://testbooru.donmai.us/\"\n",
    "\n",
    "USERNAME = 'Lighter_01'\n",
    "API_KEY = '181TrypvXuZXX1WJZScybDaf'\n",
    "\n",
    "dataset_path = os.path.join('..', 'datasets', 'extended_dataset', 'train')\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_list = [os.path.basename(x.path) for x in os.scandir(os.path.join('..', 'datasets', 'splitted', 'train'))]\n",
    "characters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(characters_list):\n",
    "    for character in characters_list:\n",
    "        os.makedirs(os.path.join(dataset_path, character), exist_ok=True)\n",
    "\n",
    "create_dirs(characters_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_tags_list = [\n",
    "    'portgas_d._ace',\n",
    "    'sakazuki_(akainu)',\n",
    "    'brook_(one_piece)',\n",
    "    'tony_tony_chopper',\n",
    "    'crocodile_(one_piece)',\n",
    "    'franky_(one_piece)',\n",
    "    'jinbe_(one_piece)',\n",
    "    'marshall_d._teach',\n",
    "    'trafalgar_law',\n",
    "    'monkey_d._luffy',\n",
    "    'dracule_mihawk',\n",
    "    'nami_(one_piece)',\n",
    "    'silvers_rayleigh',\n",
    "    'nico_robin',\n",
    "    'sanji_(one_piece)',\n",
    "    'shanks_(one_piece)',\n",
    "    'usopp',\n",
    "    'roronoa_zoro'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_dict = {k:v for k,v in zip(characters_list, character_tags_list)}\n",
    "characters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_total_images(tags, session):\n",
    "    url = BASE_URL + \"counts/posts.json\"\n",
    "    params = {\n",
    "        \"tags\": tags,\n",
    "        \"login\": USERNAME,\n",
    "        \"api_key\": API_KEY,\n",
    "    }\n",
    "    async with session.get(url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            return data.get(\"counts\", {}).get(\"posts\", 0)\n",
    "        else:\n",
    "            print(f\"Failed to fetch total count for {tags}: {response.status}\")\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_number_of_images_per_characters(characters_dict):\n",
    "    character_images_counter = {}\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for character, tag in characters_dict.items():\n",
    "            tags = f'{tag} -rating:e chartags:1'\n",
    "            print(f\"Fetching total images for: {character}\")\n",
    "            total_images = await get_total_images(tags, session)\n",
    "            character_images_counter[character] = total_images\n",
    "            print(f\"{character}: {total_images} images\")\n",
    "    return character_images_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = asyncio.run(get_number_of_images_per_characters(characters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_counter = pd.DataFrame(data=counter.items())\n",
    "characters_counter = characters_counter.T\n",
    "characters_counter.columns = characters_counter.iloc[0]\n",
    "characters_counter = characters_counter.drop(index=0).reset_index(drop=True)\n",
    "characters_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_metadata(character, page, session, delay=0.5):\n",
    "    tags = f'{character} -rating:e chartags:1'\n",
    "    params = {\n",
    "        \"page\": page,\n",
    "        \"tags\": tags,\n",
    "        \"limit\": 200,\n",
    "        \"login\": USERNAME,\n",
    "        \"api_key\": API_KEY\n",
    "    }\n",
    "    url = f'{BASE_URL}posts.json'\n",
    "    await asyncio.sleep(delay)\n",
    "    async with session.get(url, params=params) as response:\n",
    "        if response.status != 200:\n",
    "            print(f\"Failed to fetch page {page} for {character}: {response.status}\")\n",
    "            return []\n",
    "        return await response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pages = {k:((v + 199) // 200) for k,v in counter.items()}\n",
    "\n",
    "async def fetch_all_metadata(character, pages):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        urls = []\n",
    "        for page in range(1, pages + 1):\n",
    "            metadata = await fetch_metadata(characters_dict[character], page, session)\n",
    "            for post in metadata:\n",
    "                if 'file_url' in post and post['file_url'].endswith('.png'):\n",
    "                    urls.append(post['file_url'])\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_urls(characters_list):\n",
    "    images_urls_dict = {}\n",
    "    tasks = [\n",
    "        fetch_all_metadata(character, total_pages[character])\n",
    "        for character in characters_list\n",
    "    ]\n",
    "    images_urls = await asyncio.gather(*tasks)\n",
    "    \n",
    "    for i, character in enumerate(characters_list):\n",
    "        images_urls_dict[character] = images_urls[i]\n",
    "        \n",
    "    return images_urls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_urls = asyncio.run(get_urls(characters_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character, url_list in img_urls.items():\n",
    "    print(f'{character}: {len(url_list)}')\n",
    "\n",
    "print(f'Total number of urls: {sum([len(l) for l in img_urls.values()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_image(url, output_dir, session, delay=0.5):\n",
    "    try:\n",
    "        await asyncio.sleep(delay)\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                filename = os.path.join(output_dir, url.split(\"/\")[-1])\n",
    "                with open(filename, \"wb\") as f:\n",
    "                    f.write(await response.read())\n",
    "                # print(f\"Downloaded {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download {url}: {response.status}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_all_images(character, url_list):\n",
    "    output_dir = os.path.join(dataset_path, character)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for img_url in url_list:\n",
    "            tasks.append(download_image(img_url, output_dir, session))\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "    \n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_for_all_characters(img_urls_dict):\n",
    "    tasks = [\n",
    "        download_all_images(character, urls)\n",
    "        for character, urls in img_urls_dict.items()\n",
    "    ]\n",
    "    await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_for_all_characters(img_urls_dict):\n",
    "    for character, url_list in img_urls_dict.items():\n",
    "        print(character, len(url_list))\n",
    "        asyncio.run(download_all_images(character, url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asyncio.run(download_for_all_characters(img_urls))\n",
    "download_for_all_characters(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_files_in_directories(directory_path):\n",
    "    f = {}\n",
    "    for (dirpath, dirnames, filenames) in os.walk(directory_path):\n",
    "        if len(filenames) != 0:\n",
    "            character_name = dirpath.split('\\\\')[-1]\n",
    "            if character_name not in f:\n",
    "                f[character_name] = []\n",
    "            f[character_name].extend(filenames)\n",
    "    \n",
    "    for character_name, urls in f.items():\n",
    "        f[character_name] = len(urls)\n",
    "        \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_number_of_files_in_directories(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corrupted_files(dataset_root):\n",
    "    corrupted_files = []\n",
    "    for subdir, _, files in os.walk(dataset_root):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    img.verify()\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                corrupted_files.append(file_path)\n",
    "                print(f\"Corrupted file: {file_path}\")\n",
    "    return corrupted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_files = find_corrupted_files(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_corrupted_files(corrupted_files):\n",
    "    for file in corrupted_files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"Removed corrupted file: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to remove {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_corrupted_files(corrupted_files[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsl python 3.11.5",
   "language": "python",
   "name": "wsl_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
